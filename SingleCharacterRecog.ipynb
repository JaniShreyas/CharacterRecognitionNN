{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"handwritten_data_785.csv\")\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df)\n",
    "data = arr[:, 1:] / 255\n",
    "target = arr[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = keras.layers.Input(shape=[784])\n",
    "# hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "# hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "# output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "# model = keras.Model(inputs = input, outputs = output)\n",
    "\n",
    "# model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.SGD(), metrics = keras.metrics.Accuracy())\n",
    "\n",
    "XTrainFull, XTest, yTrainFull, yTest = train_test_split(data, target)\n",
    "XTrain, XValid, yTrain, yValid = train_test_split(XTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 19s 3ms/step - loss: 0.7245 - accuracy: 0.8089 - val_loss: 0.4348 - val_accuracy: 0.8837\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 14s 2ms/step - loss: 0.3673 - accuracy: 0.9032 - val_loss: 0.3099 - val_accuracy: 0.9189\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.2729 - accuracy: 0.9281 - val_loss: 0.2454 - val_accuracy: 0.9344\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.2219 - accuracy: 0.9422 - val_loss: 0.2096 - val_accuracy: 0.9448\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1902 - accuracy: 0.9502 - val_loss: 0.1857 - val_accuracy: 0.9502\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.1682 - accuracy: 0.9561 - val_loss: 0.1766 - val_accuracy: 0.9523\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.1510 - accuracy: 0.9608 - val_loss: 0.1582 - val_accuracy: 0.9577\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.1379 - accuracy: 0.9640 - val_loss: 0.1463 - val_accuracy: 0.9611\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.1273 - accuracy: 0.9676 - val_loss: 0.1412 - val_accuracy: 0.9615\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.1181 - accuracy: 0.9698 - val_loss: 0.1316 - val_accuracy: 0.9656\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.1103 - accuracy: 0.9717 - val_loss: 0.1258 - val_accuracy: 0.9666\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 16s 3ms/step - loss: 0.1034 - accuracy: 0.9737 - val_loss: 0.1207 - val_accuracy: 0.9669\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 16s 3ms/step - loss: 0.0978 - accuracy: 0.9752 - val_loss: 0.1187 - val_accuracy: 0.9682\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.0926 - accuracy: 0.9766 - val_loss: 0.1155 - val_accuracy: 0.9692\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0876 - accuracy: 0.9780 - val_loss: 0.1111 - val_accuracy: 0.9705\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.0834 - accuracy: 0.9787 - val_loss: 0.1077 - val_accuracy: 0.9717\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.0793 - accuracy: 0.9800 - val_loss: 0.1035 - val_accuracy: 0.9724\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0758 - accuracy: 0.9808 - val_loss: 0.1055 - val_accuracy: 0.9718\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0721 - accuracy: 0.9819 - val_loss: 0.1021 - val_accuracy: 0.9729\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0692 - accuracy: 0.9827 - val_loss: 0.0989 - val_accuracy: 0.9736\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0657 - accuracy: 0.9839 - val_loss: 0.0968 - val_accuracy: 0.9748\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 16s 2ms/step - loss: 0.0630 - accuracy: 0.9843 - val_loss: 0.0970 - val_accuracy: 0.9746\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 15s 2ms/step - loss: 0.0603 - accuracy: 0.9851 - val_loss: 0.0945 - val_accuracy: 0.9750\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 16s 3ms/step - loss: 0.0575 - accuracy: 0.9860 - val_loss: 0.1001 - val_accuracy: 0.9729\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 20s 3ms/step - loss: 0.0552 - accuracy: 0.9867 - val_loss: 0.0944 - val_accuracy: 0.9755\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 19s 3ms/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.0919 - val_accuracy: 0.9757\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0508 - accuracy: 0.9879 - val_loss: 0.0914 - val_accuracy: 0.9762\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.0486 - accuracy: 0.9886 - val_loss: 0.0896 - val_accuracy: 0.9763\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0465 - accuracy: 0.9891 - val_loss: 0.0904 - val_accuracy: 0.9772\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0448 - accuracy: 0.9893 - val_loss: 0.0912 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "# Build a simple mlp model\n",
    "input = keras.layers.Input(shape=[784])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(XTrain, yTrain, epochs=30, validation_data=(XValid, yValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.98 0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.02]]\n",
      "[15, 17, 11]\n"
     ]
    }
   ],
   "source": [
    "yPred = model.predict(XTest[:3]).round(2)\n",
    "print(yPred)\n",
    "print(\n",
    "    [\n",
    "        j\n",
    "        for i in range(len(yPred))\n",
    "        for j in range(len(yPred[0]))\n",
    "        if yPred[i, j] == max(yPred[i])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 1.3086 - accuracy: 0.6304 - val_loss: 0.7510 - val_accuracy: 0.7918\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.6402 - accuracy: 0.8248 - val_loss: 0.5624 - val_accuracy: 0.8497\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.5141 - accuracy: 0.8613 - val_loss: 0.4686 - val_accuracy: 0.8735\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.4391 - accuracy: 0.8833 - val_loss: 0.4060 - val_accuracy: 0.8917\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.3879 - accuracy: 0.8980 - val_loss: 0.3691 - val_accuracy: 0.8993\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.3544 - accuracy: 0.9064 - val_loss: 0.3414 - val_accuracy: 0.9090\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.3301 - accuracy: 0.9128 - val_loss: 0.3232 - val_accuracy: 0.9134\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.3118 - accuracy: 0.9176 - val_loss: 0.3075 - val_accuracy: 0.9170\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2978 - accuracy: 0.9210 - val_loss: 0.2955 - val_accuracy: 0.9218\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2869 - accuracy: 0.9241 - val_loss: 0.2890 - val_accuracy: 0.9238\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2782 - accuracy: 0.9259 - val_loss: 0.3010 - val_accuracy: 0.9206\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2708 - accuracy: 0.9280 - val_loss: 0.2838 - val_accuracy: 0.9244\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.2641 - accuracy: 0.9297 - val_loss: 0.2709 - val_accuracy: 0.9272\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2589 - accuracy: 0.9312 - val_loss: 0.2655 - val_accuracy: 0.9293\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2545 - accuracy: 0.9325 - val_loss: 0.2739 - val_accuracy: 0.9269\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2502 - accuracy: 0.9337 - val_loss: 0.2621 - val_accuracy: 0.9302\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2471 - accuracy: 0.9344 - val_loss: 0.2539 - val_accuracy: 0.9327\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2437 - accuracy: 0.9352 - val_loss: 0.2588 - val_accuracy: 0.9312\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2413 - accuracy: 0.9359 - val_loss: 0.2594 - val_accuracy: 0.9303\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.2385 - accuracy: 0.9364 - val_loss: 0.2581 - val_accuracy: 0.9306\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2358 - accuracy: 0.9372 - val_loss: 0.2511 - val_accuracy: 0.9320\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2337 - accuracy: 0.9377 - val_loss: 0.2546 - val_accuracy: 0.9328\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2315 - accuracy: 0.9379 - val_loss: 0.2500 - val_accuracy: 0.9324\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2296 - accuracy: 0.9387 - val_loss: 0.2520 - val_accuracy: 0.9325\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2278 - accuracy: 0.9390 - val_loss: 0.2439 - val_accuracy: 0.9352\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.2259 - accuracy: 0.9397 - val_loss: 0.2494 - val_accuracy: 0.9334\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2240 - accuracy: 0.9407 - val_loss: 0.2463 - val_accuracy: 0.9342\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2223 - accuracy: 0.9406 - val_loss: 0.2450 - val_accuracy: 0.9354\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2203 - accuracy: 0.9415 - val_loss: 0.2403 - val_accuracy: 0.9360\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.2186 - accuracy: 0.9416 - val_loss: 0.2424 - val_accuracy: 0.9351\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[784])\n",
    "hidden1 = keras.layers.Dense(30, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(10, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "model1 = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model1.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model1.fit(XTrain, yTrain, epochs=30, validation_data=(XValid, yValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "[15, 17, 11]\n",
      "[15 17 11]\n"
     ]
    }
   ],
   "source": [
    "yPred = model1.predict(XTest[:3])\n",
    "print(\n",
    "    [\n",
    "        j\n",
    "        for i in range(len(yPred))\n",
    "        for j in range(len(yPred[0]))\n",
    "        if yPred[i, j] == max(yPred[i])\n",
    "    ]\n",
    ")\n",
    "print(yTest[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=80)\n",
    "pca.fit(XTrain)\n",
    "variance = pca.explained_variance_\n",
    "# pd.DataFrame(variance).to_csv('Explained_variance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x284384c3460>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(variance, \"r-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = pca.components_\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainTransformed = pca.transform(XTrain)\n",
    "XValidTransformed = pca.transform(XValid)\n",
    "XTestTransformed = pca.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 64.5 GiB for an array with shape (93010, 93010) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Shreyas\\ML Projects\\CharacterRecognitionNN\\SingleCharacterRecog.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shreyas/ML%20Projects/CharacterRecognitionNN/SingleCharacterRecog.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# XTrain = np.matmul(components, XTrain.T-np.mean(XTrain.T))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shreyas/ML%20Projects/CharacterRecognitionNN/SingleCharacterRecog.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# XValid = np.matmul(components, XValid.T-np.mean(XValid.T))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shreyas/ML%20Projects/CharacterRecognitionNN/SingleCharacterRecog.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# XTest = np.matmul(components, XTest.T-np.mean(XTest.T))\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Shreyas/ML%20Projects/CharacterRecognitionNN/SingleCharacterRecog.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m np\u001b[39m.\u001b[39;49mcov(XTest)\n",
      "File \u001b[1;32mc:\\Users\\unova\\anaconda3\\envs\\jupyter\\lib\\site-packages\\numpy\\lib\\function_base.py:2747\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2746\u001b[0m     X_T \u001b[39m=\u001b[39m (X\u001b[39m*\u001b[39mw)\u001b[39m.\u001b[39mT\n\u001b[1;32m-> 2747\u001b[0m c \u001b[39m=\u001b[39m dot(X, X_T\u001b[39m.\u001b[39;49mconj())\n\u001b[0;32m   2748\u001b[0m c \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtrue_divide(\u001b[39m1\u001b[39m, fact)\n\u001b[0;32m   2749\u001b[0m \u001b[39mreturn\u001b[39;00m c\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 64.5 GiB for an array with shape (93010, 93010) and data type float64"
     ]
    }
   ],
   "source": [
    "# XTrain = np.matmul(components, XTrain.T-np.mean(XTrain.T))\n",
    "# XValid = np.matmul(components, XValid.T-np.mean(XValid.T))\n",
    "# XTest = np.matmul(components, XTest.T-np.mean(XTest.T))\n",
    "\n",
    "np.cov(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209270, 400) (69757, 400) (93010, 400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.94196815e-04, -6.53897522e-06, -9.06861064e-05, ...,\n",
       "         4.70849494e-07, -4.46724529e-06,  3.64066039e-06],\n",
       "       [-6.53897522e-06,  1.27698809e-03, -2.09581250e-06, ...,\n",
       "         1.08816256e-08, -1.03240826e-07,  8.41379331e-08],\n",
       "       [-9.06861064e-05, -2.09581250e-06,  1.24807333e-03, ...,\n",
       "         1.50912371e-07, -1.43180058e-06,  1.16687115e-06],\n",
       "       ...,\n",
       "       [ 4.70849494e-07,  1.08816256e-08,  1.50912371e-07, ...,\n",
       "         1.27713842e-03,  7.43402275e-09, -6.05848805e-09],\n",
       "       [-4.46724529e-06, -1.03240826e-07, -1.43180058e-06, ...,\n",
       "         7.43402275e-09,  1.27706868e-03,  5.74806865e-08],\n",
       "       [ 3.64066039e-06,  8.41379331e-08,  1.16687115e-06, ...,\n",
       "        -6.05848805e-09,  5.74806865e-08,  1.27709236e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XTrain = XTrain.T\n",
    "# XValid = XValid.T\n",
    "# XTest = XTest.T\n",
    "\n",
    "# print(XTrain.shape, XValid.shape, XTest.shape)\n",
    "# np.cov(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.6872 - accuracy: 0.8179 - val_loss: 0.3668 - val_accuracy: 0.9012\n",
      "Epoch 2/35\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.3016 - accuracy: 0.9195 - val_loss: 0.2645 - val_accuracy: 0.9295\n",
      "Epoch 3/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2296 - accuracy: 0.9391 - val_loss: 0.2172 - val_accuracy: 0.9426\n",
      "Epoch 4/35\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1910 - accuracy: 0.9490 - val_loss: 0.1907 - val_accuracy: 0.9491\n",
      "Epoch 5/35\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1663 - accuracy: 0.9558 - val_loss: 0.1700 - val_accuracy: 0.9547\n",
      "Epoch 6/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1487 - accuracy: 0.9605 - val_loss: 0.1564 - val_accuracy: 0.9590\n",
      "Epoch 7/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1355 - accuracy: 0.9645 - val_loss: 0.1463 - val_accuracy: 0.9607\n",
      "Epoch 8/35\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1252 - accuracy: 0.9672 - val_loss: 0.1388 - val_accuracy: 0.9628\n",
      "Epoch 9/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1166 - accuracy: 0.9694 - val_loss: 0.1319 - val_accuracy: 0.9650\n",
      "Epoch 10/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1094 - accuracy: 0.9717 - val_loss: 0.1280 - val_accuracy: 0.9661\n",
      "Epoch 11/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1032 - accuracy: 0.9735 - val_loss: 0.1230 - val_accuracy: 0.9673\n",
      "Epoch 12/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0978 - accuracy: 0.9748 - val_loss: 0.1182 - val_accuracy: 0.9690\n",
      "Epoch 13/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0928 - accuracy: 0.9762 - val_loss: 0.1160 - val_accuracy: 0.9697\n",
      "Epoch 14/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0884 - accuracy: 0.9775 - val_loss: 0.1125 - val_accuracy: 0.9702\n",
      "Epoch 15/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0844 - accuracy: 0.9789 - val_loss: 0.1096 - val_accuracy: 0.9708\n",
      "Epoch 16/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0807 - accuracy: 0.9794 - val_loss: 0.1075 - val_accuracy: 0.9716\n",
      "Epoch 17/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.0774 - accuracy: 0.9806 - val_loss: 0.1056 - val_accuracy: 0.9720\n",
      "Epoch 18/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0742 - accuracy: 0.9814 - val_loss: 0.1041 - val_accuracy: 0.9728\n",
      "Epoch 19/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0714 - accuracy: 0.9820 - val_loss: 0.1025 - val_accuracy: 0.9727\n",
      "Epoch 20/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.0687 - accuracy: 0.9828 - val_loss: 0.1001 - val_accuracy: 0.9737\n",
      "Epoch 21/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0659 - accuracy: 0.9834 - val_loss: 0.1013 - val_accuracy: 0.9735\n",
      "Epoch 22/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0636 - accuracy: 0.9842 - val_loss: 0.0985 - val_accuracy: 0.9741\n",
      "Epoch 23/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0613 - accuracy: 0.9848 - val_loss: 0.0975 - val_accuracy: 0.9742\n",
      "Epoch 24/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.0591 - accuracy: 0.9854 - val_loss: 0.0974 - val_accuracy: 0.9747\n",
      "Epoch 25/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0572 - accuracy: 0.9858 - val_loss: 0.0954 - val_accuracy: 0.9748\n",
      "Epoch 26/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.0949 - val_accuracy: 0.9752\n",
      "Epoch 27/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0535 - accuracy: 0.9867 - val_loss: 0.0930 - val_accuracy: 0.9757\n",
      "Epoch 28/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0516 - accuracy: 0.9874 - val_loss: 0.0915 - val_accuracy: 0.9758\n",
      "Epoch 29/35\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.0498 - accuracy: 0.9878 - val_loss: 0.0931 - val_accuracy: 0.9760\n",
      "Epoch 30/35\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.0484 - accuracy: 0.9883 - val_loss: 0.0911 - val_accuracy: 0.9767\n",
      "Epoch 31/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 0.0903 - val_accuracy: 0.9768\n",
      "Epoch 32/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0452 - accuracy: 0.9894 - val_loss: 0.0910 - val_accuracy: 0.9763\n",
      "Epoch 33/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0438 - accuracy: 0.9895 - val_loss: 0.0889 - val_accuracy: 0.9774\n",
      "Epoch 34/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0423 - accuracy: 0.9901 - val_loss: 0.0877 - val_accuracy: 0.9774\n",
      "Epoch 35/35\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.0412 - accuracy: 0.9903 - val_loss: 0.0896 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[80])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "modelWithPca = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithPca.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = modelWithPca.fit(XTrainTransformed, yTrain, epochs=35, validation_data=(XValidTransformed, yValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 3s 1ms/step - loss: 0.0883 - accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08834906667470932, 0.9776583313941956]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithPca.evaluate(XTestTransformed, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 1.3012 - accuracy: 0.6267 - val_loss: 0.7859 - val_accuracy: 0.7755\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.6508 - accuracy: 0.8194 - val_loss: 0.5455 - val_accuracy: 0.8488\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.4921 - accuracy: 0.8663 - val_loss: 0.4839 - val_accuracy: 0.8664\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.4180 - accuracy: 0.8863 - val_loss: 0.3861 - val_accuracy: 0.8970\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.3740 - accuracy: 0.8993 - val_loss: 0.3713 - val_accuracy: 0.8995\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.3457 - accuracy: 0.9078 - val_loss: 0.3435 - val_accuracy: 0.9093\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.3246 - accuracy: 0.9137 - val_loss: 0.3176 - val_accuracy: 0.9149\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.3083 - accuracy: 0.9176 - val_loss: 0.3063 - val_accuracy: 0.9186\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2950 - accuracy: 0.9219 - val_loss: 0.3035 - val_accuracy: 0.9183\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2838 - accuracy: 0.9242 - val_loss: 0.2970 - val_accuracy: 0.9207\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2751 - accuracy: 0.9268 - val_loss: 0.2835 - val_accuracy: 0.9245\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2681 - accuracy: 0.9282 - val_loss: 0.2791 - val_accuracy: 0.9249\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2613 - accuracy: 0.9299 - val_loss: 0.2728 - val_accuracy: 0.9279\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2552 - accuracy: 0.9322 - val_loss: 0.2709 - val_accuracy: 0.9280\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2492 - accuracy: 0.9339 - val_loss: 0.2642 - val_accuracy: 0.9292\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2451 - accuracy: 0.9345 - val_loss: 0.2628 - val_accuracy: 0.9292\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2399 - accuracy: 0.9360 - val_loss: 0.2523 - val_accuracy: 0.9325\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2364 - accuracy: 0.9366 - val_loss: 0.2553 - val_accuracy: 0.9312\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2323 - accuracy: 0.9379 - val_loss: 0.2544 - val_accuracy: 0.9308\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2287 - accuracy: 0.9388 - val_loss: 0.2471 - val_accuracy: 0.9345\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2248 - accuracy: 0.9399 - val_loss: 0.2433 - val_accuracy: 0.9354\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2217 - accuracy: 0.9408 - val_loss: 0.2478 - val_accuracy: 0.9341\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2185 - accuracy: 0.9414 - val_loss: 0.2375 - val_accuracy: 0.9359\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2154 - accuracy: 0.9422 - val_loss: 0.2370 - val_accuracy: 0.9368\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2128 - accuracy: 0.9425 - val_loss: 0.2311 - val_accuracy: 0.9376\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2097 - accuracy: 0.9436 - val_loss: 0.2322 - val_accuracy: 0.9367\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2068 - accuracy: 0.9442 - val_loss: 0.2292 - val_accuracy: 0.9379\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2042 - accuracy: 0.9446 - val_loss: 0.2269 - val_accuracy: 0.9393\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.2024 - accuracy: 0.9455 - val_loss: 0.2180 - val_accuracy: 0.9408\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 9s 1ms/step - loss: 0.1999 - accuracy: 0.9459 - val_loss: 0.2263 - val_accuracy: 0.9393\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[400])\n",
    "hidden1 = keras.layers.Dense(30, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=keras.activations.relu)(hidden1)\n",
    "hidden3 = keras.layers.Dense(10, activation=keras.activations.relu)(hidden2)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden3)\n",
    "modelWithPca = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithPca.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = modelWithPca.fit(XTrain, yTrain, epochs=30, validation_data=(XValid, yValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 3s 985us/step - loss: 0.2315 - accuracy: 0.9397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2315283566713333, 0.9397376775741577]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithPca.evaluate(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.7075 - accuracy: 0.8127 - val_loss: 0.4688 - val_accuracy: 0.8693\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.4023 - accuracy: 0.8873 - val_loss: 0.3714 - val_accuracy: 0.8956\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.3295 - accuracy: 0.9078 - val_loss: 0.3154 - val_accuracy: 0.9101\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2878 - accuracy: 0.9190 - val_loss: 0.2846 - val_accuracy: 0.9195\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2610 - accuracy: 0.9268 - val_loss: 0.2632 - val_accuracy: 0.9251\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2428 - accuracy: 0.9321 - val_loss: 0.2498 - val_accuracy: 0.9283\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2289 - accuracy: 0.9352 - val_loss: 0.2387 - val_accuracy: 0.9319\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2182 - accuracy: 0.9390 - val_loss: 0.2336 - val_accuracy: 0.9328\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2093 - accuracy: 0.9413 - val_loss: 0.2275 - val_accuracy: 0.9342\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2016 - accuracy: 0.9430 - val_loss: 0.2187 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1952 - accuracy: 0.9450 - val_loss: 0.2152 - val_accuracy: 0.9385\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1894 - accuracy: 0.9468 - val_loss: 0.2101 - val_accuracy: 0.9397\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.1843 - accuracy: 0.9480 - val_loss: 0.2060 - val_accuracy: 0.9414\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1796 - accuracy: 0.9493 - val_loss: 0.2035 - val_accuracy: 0.9421\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1754 - accuracy: 0.9504 - val_loss: 0.2011 - val_accuracy: 0.9431\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1712 - accuracy: 0.9516 - val_loss: 0.1996 - val_accuracy: 0.9429\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1674 - accuracy: 0.9530 - val_loss: 0.1953 - val_accuracy: 0.9442\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1640 - accuracy: 0.9535 - val_loss: 0.1944 - val_accuracy: 0.9439\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.1611 - accuracy: 0.9545 - val_loss: 0.1895 - val_accuracy: 0.9459\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1576 - accuracy: 0.9558 - val_loss: 0.1903 - val_accuracy: 0.9466\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1545 - accuracy: 0.9562 - val_loss: 0.1877 - val_accuracy: 0.9466\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1521 - accuracy: 0.9567 - val_loss: 0.1870 - val_accuracy: 0.9466\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1492 - accuracy: 0.9576 - val_loss: 0.1857 - val_accuracy: 0.9471\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1467 - accuracy: 0.9581 - val_loss: 0.1848 - val_accuracy: 0.9469\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 10s 1ms/step - loss: 0.1442 - accuracy: 0.9592 - val_loss: 0.1833 - val_accuracy: 0.9479\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1419 - accuracy: 0.9597 - val_loss: 0.1825 - val_accuracy: 0.9482\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1399 - accuracy: 0.9602 - val_loss: 0.1797 - val_accuracy: 0.9490\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1373 - accuracy: 0.9608 - val_loss: 0.1804 - val_accuracy: 0.9485\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1355 - accuracy: 0.9615 - val_loss: 0.1780 - val_accuracy: 0.9494\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1331 - accuracy: 0.9624 - val_loss: 0.1796 - val_accuracy: 0.9496\n",
      "2907/2907 [==============================] - 3s 1ms/step - loss: 0.1799 - accuracy: 0.9492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17992699146270752, 0.9491667747497559]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=25)\n",
    "\n",
    "XTrainLda = lda.fit_transform(XTrain, yTrain)\n",
    "XValidLda = lda.transform(XValid)\n",
    "XTestLda = lda.transform(XTest)\n",
    "\n",
    "input = keras.layers.Input(shape=[25])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "modelWithLda = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithLda.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = modelWithLda.fit(XTrainLda, yTrain, epochs=30, validation_data=(XValidLda, yValid))\n",
    "\n",
    "modelWithLda.evaluate(XTestLda, yTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
