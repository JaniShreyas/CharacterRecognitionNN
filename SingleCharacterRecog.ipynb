{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"handwritten_data_785.csv\")\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the Image data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df)\n",
    "data = arr[:, 1:] / 255\n",
    "target = arr[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainFull, XTest, yTrainFull, yTest = train_test_split(data, target)\n",
    "XTrain, XValid, yTrain, yValid = train_test_split(XTrainFull, yTrainFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply training the data without any changes\n",
    "2 hidden layers with 300 and 100 neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 21s 3ms/step - loss: 0.7192 - accuracy: 0.8102 - val_loss: 0.4311 - val_accuracy: 0.8842\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.3647 - accuracy: 0.9034 - val_loss: 0.3063 - val_accuracy: 0.9178\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.2728 - accuracy: 0.9278 - val_loss: 0.2439 - val_accuracy: 0.9350\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.2214 - accuracy: 0.9417 - val_loss: 0.2039 - val_accuracy: 0.9461\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1892 - accuracy: 0.9500 - val_loss: 0.1793 - val_accuracy: 0.9526\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1668 - accuracy: 0.9564 - val_loss: 0.1652 - val_accuracy: 0.9568\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.1503 - accuracy: 0.9605 - val_loss: 0.1516 - val_accuracy: 0.9600\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1370 - accuracy: 0.9642 - val_loss: 0.1461 - val_accuracy: 0.9603\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.1264 - accuracy: 0.9672 - val_loss: 0.1371 - val_accuracy: 0.9633\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1174 - accuracy: 0.9697 - val_loss: 0.1293 - val_accuracy: 0.9665\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.1101 - accuracy: 0.9717 - val_loss: 0.1241 - val_accuracy: 0.9676\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.1033 - accuracy: 0.9736 - val_loss: 0.1205 - val_accuracy: 0.9682\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.0975 - accuracy: 0.9750 - val_loss: 0.1259 - val_accuracy: 0.9659\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.0922 - accuracy: 0.9767 - val_loss: 0.1113 - val_accuracy: 0.9705\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 17s 3ms/step - loss: 0.0876 - accuracy: 0.9777 - val_loss: 0.1076 - val_accuracy: 0.9717\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0834 - accuracy: 0.9789 - val_loss: 0.1055 - val_accuracy: 0.9722\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0792 - accuracy: 0.9799 - val_loss: 0.1052 - val_accuracy: 0.9721\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0757 - accuracy: 0.9810 - val_loss: 0.1003 - val_accuracy: 0.9735\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0722 - accuracy: 0.9818 - val_loss: 0.1014 - val_accuracy: 0.9731\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0691 - accuracy: 0.9828 - val_loss: 0.0977 - val_accuracy: 0.9741\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.0973 - val_accuracy: 0.9743\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0631 - accuracy: 0.9843 - val_loss: 0.0930 - val_accuracy: 0.9754\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0603 - accuracy: 0.9853 - val_loss: 0.0943 - val_accuracy: 0.9753\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0580 - accuracy: 0.9856 - val_loss: 0.0914 - val_accuracy: 0.9758\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0555 - accuracy: 0.9865 - val_loss: 0.0934 - val_accuracy: 0.9753\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0530 - accuracy: 0.9871 - val_loss: 0.0878 - val_accuracy: 0.9773\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0509 - accuracy: 0.9879 - val_loss: 0.0898 - val_accuracy: 0.9763\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0488 - accuracy: 0.9883 - val_loss: 0.0889 - val_accuracy: 0.9767\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0469 - accuracy: 0.9889 - val_loss: 0.0885 - val_accuracy: 0.9767\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 18s 3ms/step - loss: 0.0450 - accuracy: 0.9895 - val_loss: 0.0843 - val_accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "# Build a simple mlp model\n",
    "input = keras.layers.Input(shape=[784])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(XTrain, yTrain, epochs=30, validation_data=(XValid, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 5s 2ms/step - loss: 0.0896 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08964746445417404, 0.977378785610199]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually checking the image to see whether prediction is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ab8815eb90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = XTest[0]\n",
    "example = example.reshape((28,28))\n",
    "plt.imshow(example, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 745ms/step\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "[4, 15, 19]\n"
     ]
    }
   ],
   "source": [
    "yPred = model.predict(XTest[:3]).round(2)\n",
    "print(yPred)\n",
    "print(\n",
    "    [\n",
    "        j\n",
    "        for i in range(len(yPred))\n",
    "        for j in range(len(yPred[0]))\n",
    "        if yPred[i, j] == max(yPred[i])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data with 10 times less neurons in the hidden layers to see the difference in training time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 58s 9ms/step - loss: 1.0885 - accuracy: 0.6959 - val_loss: 0.6299 - val_accuracy: 0.8243\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.5494 - accuracy: 0.8518 - val_loss: 0.4794 - val_accuracy: 0.8710\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.4555 - accuracy: 0.8782 - val_loss: 0.4218 - val_accuracy: 0.8875\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.4093 - accuracy: 0.8908 - val_loss: 0.4051 - val_accuracy: 0.8903\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3790 - accuracy: 0.8988 - val_loss: 0.3935 - val_accuracy: 0.8908\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3570 - accuracy: 0.9043 - val_loss: 0.3571 - val_accuracy: 0.9039\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3399 - accuracy: 0.9084 - val_loss: 0.3352 - val_accuracy: 0.9100\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3259 - accuracy: 0.9126 - val_loss: 0.3306 - val_accuracy: 0.9107\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3136 - accuracy: 0.9155 - val_loss: 0.3185 - val_accuracy: 0.9139\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3023 - accuracy: 0.9190 - val_loss: 0.3053 - val_accuracy: 0.9171\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2924 - accuracy: 0.9219 - val_loss: 0.2973 - val_accuracy: 0.9190\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2835 - accuracy: 0.9239 - val_loss: 0.2893 - val_accuracy: 0.9219\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2753 - accuracy: 0.9261 - val_loss: 0.2785 - val_accuracy: 0.9248\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2684 - accuracy: 0.9281 - val_loss: 0.2705 - val_accuracy: 0.9275\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2617 - accuracy: 0.9301 - val_loss: 0.2685 - val_accuracy: 0.9272\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2566 - accuracy: 0.9314 - val_loss: 0.2633 - val_accuracy: 0.9293\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2509 - accuracy: 0.9328 - val_loss: 0.2600 - val_accuracy: 0.9308\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2460 - accuracy: 0.9340 - val_loss: 0.2573 - val_accuracy: 0.9300\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2416 - accuracy: 0.9353 - val_loss: 0.2537 - val_accuracy: 0.9314\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2374 - accuracy: 0.9363 - val_loss: 0.2518 - val_accuracy: 0.9323\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2340 - accuracy: 0.9376 - val_loss: 0.2478 - val_accuracy: 0.9342\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2308 - accuracy: 0.9384 - val_loss: 0.2395 - val_accuracy: 0.9364\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2277 - accuracy: 0.9387 - val_loss: 0.2474 - val_accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2247 - accuracy: 0.9399 - val_loss: 0.2425 - val_accuracy: 0.9347\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2218 - accuracy: 0.9403 - val_loss: 0.2365 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2197 - accuracy: 0.9416 - val_loss: 0.2355 - val_accuracy: 0.9381\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2165 - accuracy: 0.9421 - val_loss: 0.2345 - val_accuracy: 0.9366\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2149 - accuracy: 0.9427 - val_loss: 0.2301 - val_accuracy: 0.9389\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2127 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9399\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2107 - accuracy: 0.9434 - val_loss: 0.2267 - val_accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[784])\n",
    "hidden1 = keras.layers.Dense(30, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(10, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "model1 = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "model1.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model1.fit(XTrain, yTrain, epochs=30, validation_data=(XValid, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 4s 1ms/step - loss: 0.2327 - accuracy: 0.9387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23269116878509521, 0.9387485384941101]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n",
      "[4, 15, 19]\n",
      "[ 4 15 19]\n"
     ]
    }
   ],
   "source": [
    "yPred = model1.predict(XTest[:3])\n",
    "print(\n",
    "    [\n",
    "        j\n",
    "        for i in range(len(yPred))\n",
    "        for j in range(len(yPred[0]))\n",
    "        if yPred[i, j] == max(yPred[i])\n",
    "    ]\n",
    ")\n",
    "print(yTest[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Feature extraction using Principal Component Analysis on the data to reduce complexity of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the data and Plotting the Scree Graph to find the optimal dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab88419310>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(XTrain)\n",
    "variance = pca.explained_variance_\n",
    "\n",
    "plt.plot(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Graph flattens at approximately 80 dimensions, that's what we will go with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=80)\n",
    "pca.fit(XTrain)\n",
    "variance = pca.explained_variance_\n",
    "# pd.DataFrame(variance).to_csv('Explained_variance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still reduce more but it is not really needed (80 to 70 will not give that much of a difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab88183c90>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtWElEQVR4nO3deXSU9b3H8c8kIZNAkglbAoGwKgIiimxFbK2K9VK0LpRrLe1F6YY3VhBrxXoUPT0aWs/1ul5cL/QUFTdA661SRYFjBQUkKi4sskWBgCKZEGACmd/949fJAgEyk2fmyTzzfp3zO89k1u/TaZlPv8/v9zw+Y4wRAACAA9LcLgAAAHgHwQIAADiGYAEAABxDsAAAAI4hWAAAAMcQLAAAgGMIFgAAwDEECwAA4JiMRH9gOBzWjh07lJubK5/Pl+iPBwAAMTDGqKqqSkVFRUpLO35fIuHBYseOHSouLk70xwIAAAeUl5ere/fux3084cEiNzdXki0sLy8v0R8PAABiEAwGVVxcXPc7fjwJDxaRwx95eXkECwAAkszJpjEweRMAADiGYAEAABxDsAAAAI4hWAAAAMcQLAAAgGMIFgAAwDEECwAA4BiCBQAAcAzBAgAAOIZgAQAAHEOwAAAAjiFYAAAAx3gnWMycKV13nVRR4XYlAACkLO8Ei8cflx59VNq50+1KAABIWd4JFpFLsFdWulsHAAApLKpg0atXL/l8vmNGSUlJvOprvkDAboNBd+sAACCFZUTz5FWrVqm2trbu73Xr1umiiy7ShAkTHC8sapFgQccCAADXRBUsOnfu3OjvWbNmqW/fvjrvvPMcLSomkUMhdCwAAHBNVMGioZqaGs2bN0/Tp0+Xz+c77vNCoZBCoVDd38F4/fDTsQAAwHUxT95ctGiR9u3bp2uuueaEzystLVUgEKgbxcXFsX7kiTF5EwAA18UcLJ566imNHTtWRUVFJ3zerbfeqsrKyrpRXl4e60eeGJM3AQBwXUyHQrZt26Y333xTCxYsOOlz/X6//H5/LB8THToWAAC4LqaOxZw5c1RQUKBx48Y5XU/s6FgAAOC6qINFOBzWnDlzNGnSJGVkxDz303lM3gQAwHVRB4s333xT27dv1+TJk+NRT+xYbgoAgOuibjn84Ac/kDEmHrW0DB0LAABcx7VCAACAY7wTLBpO3myNHRUAAFKAd4JFpGNRWysdOOBuLQAApCjvBIucHCntX7vDBE4AAFzhnWDh8zHPAgAAl3knWEgsOQUAwGXeChYsOQUAwFXeChYcCgEAwFXeChZcLwQAAFd5K1jQsQAAwFXeChZ0LAAAcJU3gwUdCwAAXOGtYMFyUwAAXOWtYEHHAgAAV3krWDB5EwAAV3krWDB5EwAAV3kzWNCxAADAFd4KFkzeBADAVd4KFnQsAABwlbeCRaRjUV0t1da6WwsAACnIm8FC4nAIAAAu8Faw8PvtkDgcAgCAC7wVLCSWnAIA4CLvBgs6FgAAJJz3ggVLTgEAcI33ggUdCwAAXOO9YEHHAgAA13gvWNCxAADANd4LFlzhFAAA13gvWLDcFAAA13g3WNCxAAAg4bwXLJi8CQCAa7wXLOhYAADgGu8FCzoWAAC4xnvBgo4FAACu8V6wYLkpAACu8V6waLjc1Bh3awEAIMVEHSy++uor/exnP1PHjh2VnZ2tM844Q6tXr45HbbGJBIvDh6VDh9ytBQCAFJMRzZO//fZbjR49Wueff75ee+01de7cWRs3blT79u3jVV/0cnIkn892K4JBKTvb7YoAAEgZUQWLP/3pTyouLtacOXPq7uvdu7fjRbVIWpqUm2tDRWWlVFjodkUAAKSMqA6FvPLKKxo2bJgmTJiggoICDRkyRE888cQJXxMKhRQMBhuNuGPJKQAArogqWGzevFmzZ8/WqaeeqsWLF+u6667TDTfcoL/85S/HfU1paakCgUDdKC4ubnHRJ8WSUwAAXOEzpvlLJzIzMzVs2DC9++67dffdcMMNWrVqlVasWNHka0KhkEKhUN3fwWBQxcXFqqysVF6ks+C0c86RVqyQXnpJuvLK+HwGAAApJBgMKhAInPT3O6qORdeuXTVw4MBG9w0YMEDbt28/7mv8fr/y8vIajbjjCqcAALgiqmAxevRorV+/vtF9GzZsUM+ePR0tqsU4FAIAgCuiChY33nijVq5cqXvuuUebNm3SM888o8cff1wlJSXxqi82TN4EAMAVUQWL4cOHa+HChXr22Wc1aNAg/fGPf9T999+viRMnxqu+2NCxAADAFVGdx0KSLrnkEl1yySXxqMU5dCwAAHCF964VItGxAADAJd4MFlzhFAAAV3gzWLDcFAAAV3g7WNCxAAAgobwZLJi8CQCAK7wZLOhYAADgCm8Gi0jHoqpKCofdrQUAgBTizWAR6VhINlwAAICE8Gaw8PulNm3sbQ6HAACQMN4MFj4fS04BAHCBN4OFxAROAABc4N1gwZJTAAASzrvBgo4FAAAJ591gQccCAICE826woGMBAEDCeTdYcIVTAAASzrvBguWmAAAknPeDBR0LAAASxrvBgsmbAAAknHeDBR0LAAASzrvBgo4FAAAJ591gQccCAICEI1gAAADHeDdYcCgEAICE826wiHQsQiE7AABA3Hk3WOTm1t+mawEAQEJ4N1ikp0s5OfY28ywAAEgI7wYLiXkWAAAkmLeDBStDAABIKIIFAABwjLeDBYdCAABIKG8HCzoWAAAklLeDBR0LAAASytvBgo4FAAAJ5e1gEelYECwAAEgIbweLSMeCQyEAACREVMHizjvvlM/nazT69+8fr9pajkMhAAAkVEa0Lzj99NP15ptv1r9BRtRvkThM3gQAIKGiTgUZGRnq0qVLPGpxHh0LAAASKuo5Fhs3blRRUZH69OmjiRMnavv27Sd8figUUjAYbDQSJhIsvv02cZ8JAEAKiypYjBw5UnPnztXrr7+u2bNna8uWLfrud7+rqqqq476mtLRUgUCgbhQXF7e46Gbr1ctud+yQDhxI3OcCAJCifMYYE+uL9+3bp549e+q+++7TL37xiyafEwqFFAqF6v4OBoMqLi5WZWWl8iJzIOLFGKlTJ2nvXmntWumss+L7eQAAeFQwGFQgEDjp73eLlpvm5+erX79+2rRp03Gf4/f7lZeX12gkjM8nDRhgb3/2WeI+FwCAFNWiYLF//3598cUX6tq1q1P1OI9gAQBAwkQVLH73u99p2bJl2rp1q959911dccUVSk9P19VXXx2v+loucp6Nzz93tw4AAFJAVMtNv/zyS1199dX65ptv1LlzZ5177rlauXKlOnfuHK/6Wo6OBQAACRNVsJg/f3686oifSLDYsEE6ckRqzSf0AgAgyXn7WiGS1LOnlJUl1dRIW7e6XQ0AAJ7m/WCRliaddpq9zeEQAADiyvvBQmKeBQAACZJawYKVIQAAxFVqBIvIklM6FgAAxFVqBIuGh0JiP4M5AAA4idQIFqeeaidxVlZKFRVuVwMAgGelRrDIypJ697a3ORwCAEDcpEawkFgZAgBAAqResGBlCAAAcZM6wYKVIQAAxF3qBAsOhQAAEHepFyy++kqqqnK3FgAAPCp1gkV+vtSli73NPAsAAOIidYKFxDwLAADiLLWCBStDAACIq9QMFnQsAACIi9QKFhwKAQAgrlIrWEQ6Fl98IR0+7G4tAAB4UGoFi27dpJwc6cgRadMmt6sBAMBzUitY+HwcDgEAII5SK1hIrAwBACCOUjdY0LEAAMBxqRcsOBQCAEDcpF6waHgoxBh3awEAwGNSL1j07StlZEjV1dKXX7pdDQAAnpJ6waJNG+mUU+xtDocAAOCo1AsWEhM4AQCIk9QMFpEJnBs2uFsHAAAek5rBomtXu92zx906AADwmNQMFh072u3eve7WAQCAx6RmsOjQwW6/+cbdOgAA8JjUDBZ0LAAAiIvUDBZ0LAAAiIvUDhbV1VIo5G4tAAB4SGoGi0BASvvXrnM4BAAAx6RmsEhLk9q3t7cJFgAAOKZFwWLWrFny+XyaNm2aQ+UkUGQCJ/MsAABwTMzBYtWqVXrsscc0ePBgJ+tJnMg8CzoWAAA4JqZgsX//fk2cOFFPPPGE2kcOKSQbOhYAADgupmBRUlKicePGacyYMSd9bigUUjAYbDRaBToWAAA4LiPaF8yfP18ffPCBVq1a1aznl5aW6q677oq6sLijYwEAgOOi6liUl5dr6tSpevrpp5WVldWs19x6662qrKysG+Xl5TEV6jg6FgAAOC6qjsWaNWu0e/dunX322XX31dbWavny5Xr44YcVCoWUnp7e6DV+v19+v9+Zap1ExwIAAMdFFSwuvPBCffzxx43uu/baa9W/f3/dcsstx4SKVo2OBQAAjosqWOTm5mrQoEGN7mvXrp06dux4zP2tHh0LAAAcl5pn3pToWAAAEAdRrwo52tKlSx0owwV0LAAAcBwdi0OHpIMH3a0FAACPSN1gkZsrZfyrYUPXAgAAR6RusPD5mGcBAIDDUjdYSMyzAADAYakdLOhYAADgqNQOFnQsAABwVGoHCzoWAAA4KrWDBR0LAAAcldrBgo4FAACOSu1gQccCAABHpXawoGMBAICjUjtY0LEAAMBRqR0s6FgAAOCo1A4WDTsWxrhbCwAAHpDawSLSsTh8WKqudrcWAAA8ILWDRdu2kt9vbzPPAgCAFkvtYMEVTgEAcFRqBwupPljQsQAAoMUIFpEJnHQsAABoMYIFHQsAABxDsKBjAQCAYwgWdCwAAHAMwYKOBQAAjiFY0LEAAMAxBAs6FgAAOIZgQccCAADHECzoWAAA4BiCRcNTenOFUwAAWoRgEQkWtbVSMOhuLQAAJDmCRXa2HRLzLAAAaCGChcQ8CwAAHEKwkFgZAgCAQwgWEh0LAAAcQrCQ6FgAAOAQgoVExwIAAIcQLCQ6FgAAOIRgIdGxAADAIVEFi9mzZ2vw4MHKy8tTXl6eRo0apddeey1etSUOHQsAABwRVbDo3r27Zs2apTVr1mj16tW64IILdNlll+mTTz6JV32JQccCAABHZETz5EsvvbTR33fffbdmz56tlStX6vTTT3e0sISiYwEAgCOiChYN1dbW6oUXXlB1dbVGjRp13OeFQiGFQqG6v4Ot8XocdCwAAHBE1JM3P/74Y+Xk5Mjv92vKlClauHChBg4ceNznl5aWKhAI1I3i4uIWFRwXkY7Ft9/ai5EBAICY+IyJ7lrhNTU12r59uyorK/Xiiy/qySef1LJly44bLprqWBQXF6uyslJ5eXktq94pNTWS329vf/NNfdAAAACS7O93IBA46e931MHiaGPGjFHfvn312GOPOVpYwuXmSvv3Sxs2SKee6nY1AAC0Ks39/W7xeSzC4XCjjkTSYp4FAAAtFtXkzVtvvVVjx45Vjx49VFVVpWeeeUZLly7V4sWL41Vf4nToIG3bxsoQAABaIKpgsXv3bv3Hf/yHdu7cqUAgoMGDB2vx4sW66KKL4lVf4tCxAACgxaIKFk899VS86nAf57IAAKDFuFZIBB0LAABajGARQccCAIAWI1hERIIFHQsAAGJGsIiIHAqhYwEAQMwIFhF0LAAAaDGCRQQdCwAAWoxgEUHHAgCAFiNYREQ6FpWV0pEj7tYCAECSIlhEtG9ff/vbb92rAwCAJEawiMjIkAIBe5t5FgAAxIRg0RDzLAAAaBGCRUOdO9vthx+6WwcAAEmKYNHQv/+73d55p53ECQAAokKwaOi3v5VOO03avduGCwAAEBWCRUOZmdIDD9jbDz0kffqpu/UAAJBkCBZHu/hi6bLLpNpa6YYbJGPcrggAgKRBsGjKffdJfr+0ZIm0cKHb1QAAkDQIFk3p00e6+WZ7e/p06cABd+sBACBJECyO59ZbpeJiads26c9/drsaAACSAsHieNq2lf7rv+ztP/1J2rrV1XIAAEgGBIsT+fGPpfPPlw4dkm66ye1qAABo9QgWJ+LzSQ8+aLcLFtC1AADgJAgWJzNokHTeefb288+7WwsAAK0cwaI5rrrKbp97zt06AABo5QgWzTF+vJSeLn3wgbRpk9vVAADQahEsmqNzZ+mCC+xtDocAAHBcBIvmilz5lMMhAAAcF8Giua68UsrIkD76SPr8c7erAQCgVSJYNFeHDtJFF9nbHA4BAKBJBItosDoEAIATIlhE47LLpMxM6dNPpU8+cbsaAABaHYJFNPLzpYsvtrfpWgAAcAyCRbQaHg4xxt1aAABoZQgW0br0UsnvlzZssCtEAABAHYJFtPLypB/+0N7mcAgAAI0QLGLB4RAAAJoUVbAoLS3V8OHDlZubq4KCAl1++eVav359vGprvS65RMrOljZvltascbsaAABajaiCxbJly1RSUqKVK1fqjTfe0OHDh/WDH/xA1dXV8aqvdWrXzoYLSZo3z91aAABoRXzGxN7L37NnjwoKCrRs2TJ973vfa9ZrgsGgAoGAKisrlZeXF+tHu+9vf5N+9CMpLU1avFgaM8btigAAiJvm/n63aI5FZWWlJKlDhw4teZvkdMkl0jXXSOGwnXOxZYvbFQEA4LqYg0U4HNa0adM0evRoDRo06LjPC4VCCgaDjYYn+HzS7NnS8OHS3r3SFVdIqXZICACAo8QcLEpKSrRu3TrNnz//hM8rLS1VIBCoG8XFxbF+ZOuTlSUtWCAVFEgffij94hesEgEApLSY5lhcf/31evnll7V8+XL17t37hM8NhUIKhUJ1fweDQRUXFyf/HIuG3nlHOv986cgR6c9/lm6+2e2KAABwVFzmWBhjdP3112vhwoV66623ThoqJMnv9ysvL6/R8Jxzz5UefNDenjFD+sc/3K0HAACXRBUsSkpKNG/ePD3zzDPKzc3Vrl27tGvXLh08eDBe9SWPKVOkX/7STub8yU+ke+6R3n1XqqlxuzIAABImqkMhPp+vyfvnzJmja665plnv4Znlpk0JhewhkRUr6u9r21YaPVr6/vel8eOl005zrTwAAGLV3N/vFp3HIhaeDhaStH+/9Je/SEuX2vH11/WPZWdLZWVSv34uFQcAQGwSch4LNCEnRyopkV54QaqokD7+WHroIemMM6SDB6W773a7QgAA4oaORaKsWiWNGCGlp0uffy6dcorbFQEA0Gx0LFqb4cOlsWOl2lq6FgAAzyJYJNLMmXb7179KX3zhbi0AAMQBwSKRRo6ULr7Ydi1KS92uBgAAxxEsEi3StfjLX6StW10tBQAApxEsEm3UKHuJ9SNH7Em0AADwEIKFGyJdi7lzpW3bXC0FAAAnESzccO650gUXSIcPS7NmuV0NAACOIVi4JdK1eOopqbzc3VoAAHAIwcIt3/uevX7I4cOsEAEAeAbBwk2RrsVjj0nvv+9uLQAAOIBg4abvf1/66U/tpdYnT7ZXRwUAIIkRLNz2wANS587SJ59wqm8AQNIjWLitUyfpkUfs7dJSe1l1AACSFMGiNZgwQRo/3p40a/JkO6ETAIAkRLBoLR5+WOrQQVq7Vrr3XrerAQAgJgSL1qJLFzvfQpLuukv69FN36wEAIAYEi9Zk4kRp3DippsYeEqmtdbsiAACikuF2AWjA55MefVQ6/XTpvfekbt2kIUOks86qH6ecIqWnu1woAABN8xljTCI/MBgMKhAIqLKyUnl5eYn86OTx3HPSpElNn9eia1dp1SobOgAASJDm/n5zKKQ1uuoq6ZtvpBUrpNmzpd/8Rho5UsrKknbulObNc7tCAACaRMcimTz2mDRlijRsmO1aAACQIHQsvOjyy6W0NGn1amnrVrerAQDgGASLZFJYaK+KKkkvveRuLQAANIFgkWx+/GO7ffFFd+sAAKAJBItkc8UVdlnqypVSebnb1QAA0AjBItkUFUmjR9vbCxa4WwsAAEchWCQjDocAAFopgkUyuvJKu/3nP6UdO9ytBQCABggWyai4WPrOdyRjpIUL3a4GAIA6BItkNWGC3XI4BADQihAsktX48Xa7fLlUUeFuLQAA/AvBIln17CkNHy6Fw9KiRW5XAwCAJIJFcmN1CACglSFYJLPI4ZC335a+/trdWgAAEMEiufXtKw0ZItXWSi+/7HY1AABEHyyWL1+uSy+9VEVFRfL5fFrE8X13RQ6HPPig9Mgj0t//Ln32mXTwoLt1AQBSUtTBorq6WmeeeaYeeeSReNSDaEWCxUcfSddfL40bJw0cKLVtK3XrJt18s/Ttt+7WCABIGT5jjIn5xT6fFi5cqMsvv7zZrwkGgwoEAqqsrFReXl6sH42GXnlFWrpU2rxZ2rLFjqqq+sfbt5duu80GD7/ftTIBAMmrub/fcZ9jEQqFFAwGGw047Ec/ku67zy47/fBDqbLSTuZ8+WVp0CDbsfjd76T+/aVnnrFLVAEAiIO4B4vS0lIFAoG6UVxcHO+PhM8ndexoA0dZmfTUU/aqqFu3ShMnSmedJf3qV9I999igsWKFtHOnPUU4AAAtEPdDIaFQSKFQqO7vYDCo4uJiDoUk2oED0v33S7NmNT5M0lD37tLvf29DR1ZWQssDALRuzT0UwhyLVLNnj/T663Y+xtatdj7G1q1SeXn9IZKuXaVbbpF+/WspO9vNagEArURzf78zElgTWoPOnaWf//zY+w8dkubOtYdHysuladOk0lLbwfjNb6R27RJdKQAgCUU9x2L//v0qKytTWVmZJGnLli0qKyvT9u3bna4NiZSVJU2ZIm3aJD32mL0WSUWFdNNN9vYdd0i7d7tdJQCglYv6UMjSpUt1/vnnH3P/pEmTNHfu3JO+nkMhSaKmRvrrX20HY/Nme19WljRpkjR9utSvn7v1AQASKiFzLGJBsEgytbXSggXSvfdKq1bZ+3w+6bLLpN/+Vjr/fPs3AMDTWs15LJDk0tOlCROk996Tli2TLrnELktdtEi68EJ7boz77pO++cbtSgEArQDBAs3j80nf+570t79Jn35q52Pk5EgbNth5GN262Umhy5fbLgcAICVxKASxq6qSnn1WevRRae3a+vsLC+3JuS6/XLrgAs6JAQAewBwLJI4xdv7FY49JL71kTykekZMjjR0rXXqpdPHFUkGBe3UCAGJGsIA7amrsXIxFi+zYsaP+MZ9PGjrUBo2xY6URI+wcDgBAq0ewgPvCYWnNGhsw/v53e92Shtq3l/r2tV2MwsL6bdeu0imnSKeeKgUCblQOADgKwQKtz86d9nTir70mvfGGtG/fyV9TUGDPmdGvnzRmjPSTn7C8FQBcQLBA63bkiPTRR/ZQSUWFPatnRYUdX34pbdxobx9t/HjpySel/PyElwwAqYxggeQXDNqAsWGD9MEH0gMPSIcPS716Sc89Z+doAAASghNkIfnl5dnJnldfbc/8+c9/Sr1726uxjh5tT8yV2FwMADgJggWSx/Dh9nwZP/6xPZRy0032fBnr1xMwAKCVIFgguQQC0vPPS//zP5LfL736qj2teMeO0r/9mzRzpl2BwinGAcAVzLFA8iork268UVqxQgqFGj/m89lrmUyebM8Amp3tRoUA4BlM3kTqqKmxK0zee69+bNhQ/3h+vvTTn9qQcfbZLFcFgBgQLJDatmyR5s6V5syRysvr7z/zTOmGG2zQ4BomANBsrApBauvdW7rrLhsw/vEPe2Itv1/68EPpF7+QevaU7ryz6XNlAABiRrCAt6WnSxddZK/CumOH9Kc/Sd272xNy3XWX1KOHdO210ttvS9XVblcLAEmPQyFIPYcPSwsWSP/933Y+RkR6ujRkiHTOOXaMHm1DCACAORZAs6xcaZeuvvWW9NVXxz7erZv0ne9II0fa7dChUtu2ia8TAFxGsACiVV5uz+757rt2lJVJtbWNnxPpalx2mb1uyYABrpQKAIlGsABaqrraXvb9vfdsZ2PlSjtPo6EBA2zAGD/erjhhKSsAjyJYAPFQXm4v+f7SS3Z7+HD9Y7m5UteuUpcu9aOw0J4VND9fat++ftuxo90SRAAkCYIFEG/79tlTir/0kvT669KhQ9G9Pj9fOvXU+tGvn9Snj53X0aWL1KZNPKoGgJgQLIBEOnhQ2rbNnhdj16767a5d0rff1o99++y2qurE7+fz2W5Ht252tGsnZWTYOR7p6fZ2ZqbUt689HDNggF3BQgcEQJwQLIDW7MAB6YsvpI0b7diwwW63bbPzOI4cif49c3LsBdlOO00qLrZBo+G2UyeCB4CYESyAZBUOS3v22OWvO3bY7cGDNmzU1tpx5IgNJxs2SJ99Jm3adPIw0qaN7YI0nP8R2RYWSgUF9beZ/wHgKM39/c5IYE0AmiMtrf4H/uyzm/eamhobLiIh46uvpC+/tKO83B6aOXy4/r6TSU+X8vLqRyBQv+3QwQaPhtvIiPzt97fsPwMASYtgAXhBZqY0cKAdTampsacxj8z7aDgqKuzYvdtu9+2zXZHIvJBYtG1rD73061c/B2TAAFtf5850QwAP41AIgMZCIembb6Rg0I7KyvptZaW0d68NHMfbhsMnfv/IstyGh2K6dLHXbYmsjunQITH7CqDZOBQCIDZ+v1RUZEe0wuH68LFrl7R+vT088+mndrt1q10RU1Vl54ccT4cONmSccooNIZ06NR7t29uVMu3a2e5IdjZdEKCVoGMBIHEOHJC2b296We6WLXZlTFPXbGmOtm1tIOnWzYaiyFLdhst1MzLsJNbIct2cHNtBycuzW+aGAMdFxwJA69O2rV0S27//8Z9TXV2/FPeLL+zcj6+/bjz27rUhJRSqf92BA3Y0Z3Lq8bRpY7shBQWNR2GhPaFZZDJrwzCSnS1lZdVvM/hnFamN/wUAaF3atZMGD7bjZGpr6wNFdbUNHV99VT927LDj0CG7KubIkfptKCTt328Pyxw4YN/v8GEbZHbvjr3+jAwboAIBG0Yi2/x82yFpGEKys+1o06bxyMw89nbD+yJdl4bb7Gz7uenpsdcOOIBgASB5pafbrkFurv27T5/Y3ufIERsygkHbDdmzpz5gRMa+fTaEBIONtwcP2lU3Dd8rMvG1vLzFuxg1v7/x/JPMzGNDSXa2DTxHh5/IoaDIfBWfz46srPr3i2xzcuo7OIQZNECwAICMjPquQo8e0b8+HLZdkUOHbNCorraTWPftq9/u22fvP3iw/nmR7eHDdtTU1N8++r6amvrbR4407r40PDlaKGTH3r2O/EfTLDk59UGlXbumuy1t29oAGJnXkpNjn5uebs/d0nBE5sA0Nfz+xiMry74X19ZpNQgWANBSaWn2h7NtW3c+3xgbUqqrG48DB5oOLAcO1C8fbhiAamrse0XeU6oPTZH3ixx22r+//sJ7+/fbEevEWydkZzee/xIJGycaDTs5aWm2OxPZRm5nZR07MjPrD0E1PBzVsLMT6e5kZaXciiWCBQAkO5+vfr5Gp06J+9yamsYBpbKyPsw0DDShkL0/MqclEkT277fBJRy2QSZyu+HrIyPSiTl6RALQwYN2VFQkbv+bKxI+Gs6LychoHGSO7tpELjgYud3UfRkZTQefrCzp9tttB84FMQWLRx55RPfee6927dqlM888Uw899JBGjBjhdG0AgNYsM9OeSbVzZ3c+3xgbQCLzYyIjEl6OPqzU1IiEn0i4iQQcY+zk4Jqa+sNckREKNT4UFXmvhp2dhiuWIo8n0u9/n9jPayDqYPHcc89p+vTpevTRRzVy5Ejdf//9uvjii7V+/XoVFBTEo0YAAI7l89lwE7lWTWtSW1s/3+boOTGRbcMQEw7b10QCTeTv420jFyMMhY4NPocO1U9odkHUJ8gaOXKkhg8frocffliSFA6HVVxcrN/+9reaMWPGSV/PCbIAAEg+zf39TovmTWtqarRmzRqNGTOm/g3S0jRmzBitWLGiydeEQiEFg8FGAwAAeFNUweLrr79WbW2tCgsLG91fWFioXbt2Nfma0tJSBQKBulFcXBx7tQAAoFWLKljE4tZbb1VlZWXdKHfjhDEAACAhopq82alTJ6Wnp6viqOU8FRUV6tKlS5Ov8fv98nNhHwAAUkJUHYvMzEwNHTpUS5YsqbsvHA5ryZIlGjVqlOPFAQCA5BL1ctPp06dr0qRJGjZsmEaMGKH7779f1dXVuvbaa+NRHwAASCJRB4urrrpKe/bs0R133KFdu3bprLPO0uuvv37MhE4AAJB6oj6PRUtxHgsAAJJPXM5jAQAAcCIECwAA4BiCBQAAcAzBAgAAOIZgAQAAHBP1ctOWiixC4WJkAAAkj8jv9skWkyY8WFRVVUkSFyMDACAJVVVVKRAIHPfxhJ/HIhwOa8eOHcrNzZXP53PsfYPBoIqLi1VeXu7Z82Owj97APnpHKuwn++gNTuyjMUZVVVUqKipSWtrxZ1IkvGORlpam7t27x+398/LyPPtfjAj20RvYR+9Ihf1kH72hpft4ok5FBJM3AQCAYwgWAADAMZ4JFn6/XzNnzpTf73e7lLhhH72BffSOVNhP9tEbErmPCZ+8CQAAvMszHQsAAOA+ggUAAHAMwQIAADiGYAEAABzjmWDxyCOPqFevXsrKytLIkSP1/vvvu11SzJYvX65LL71URUVF8vl8WrRoUaPHjTG644471LVrV2VnZ2vMmDHauHGjO8XGqLS0VMOHD1dubq4KCgp0+eWXa/369Y2ec+jQIZWUlKhjx47KycnR+PHjVVFR4VLF0Zs9e7YGDx5cd0KaUaNG6bXXXqt7PNn372izZs2Sz+fTtGnT6u7zwj7eeeed8vl8jUb//v3rHvfCPkrSV199pZ/97Gfq2LGjsrOzdcYZZ2j16tV1jyf7vzu9evU65nv0+XwqKSmR5I3vsba2Vrfffrt69+6t7Oxs9e3bV3/84x8bXdsjId+j8YD58+ebzMxM87//+7/mk08+Mb/61a9Mfn6+qaiocLu0mPz97383t912m1mwYIGRZBYuXNjo8VmzZplAIGAWLVpkPvzwQ/OjH/3I9O7d2xw8eNCdgmNw8cUXmzlz5ph169aZsrIy88Mf/tD06NHD7N+/v+45U6ZMMcXFxWbJkiVm9erV5jvf+Y4555xzXKw6Oq+88or5v//7P7Nhwwazfv1684c//MG0adPGrFu3zhiT/PvX0Pvvv2969eplBg8ebKZOnVp3vxf2cebMmeb00083O3furBt79uype9wL+7h3717Ts2dPc80115j33nvPbN682SxevNhs2rSp7jnJ/u/O7t27G32Hb7zxhpFk3n77bWOMN77Hu+++23Ts2NG8+uqrZsuWLeaFF14wOTk55oEHHqh7TiK+R08EixEjRpiSkpK6v2tra01RUZEpLS11sSpnHB0swuGw6dKli7n33nvr7tu3b5/x+/3m2WefdaFCZ+zevdtIMsuWLTPG2H1q06aNeeGFF+qe89lnnxlJZsWKFW6V2WLt27c3Tz75pKf2r6qqypx66qnmjTfeMOedd15dsPDKPs6cOdOceeaZTT7mlX285ZZbzLnnnnvcx734787UqVNN3759TTgc9sz3OG7cODN58uRG91155ZVm4sSJxpjEfY9JfyikpqZGa9as0ZgxY+ruS0tL05gxY7RixQoXK4uPLVu2aNeuXY32NxAIaOTIkUm9v5WVlZKkDh06SJLWrFmjw4cPN9rP/v37q0ePHkm5n7W1tZo/f76qq6s1atQoT+1fSUmJxo0b12hfJG99hxs3blRRUZH69OmjiRMnavv27ZK8s4+vvPKKhg0bpgkTJqigoEBDhgzRE088Ufe41/7dqamp0bx58zR58mT5fD7PfI/nnHOOlixZog0bNkiSPvzwQ73zzjsaO3aspMR9jwm/CJnTvv76a9XW1qqwsLDR/YWFhfr8889dqip+du3aJUlN7m/ksWQTDoc1bdo0jR49WoMGDZJk9zMzM1P5+fmNnpts+/nxxx9r1KhROnTokHJycrRw4UINHDhQZWVlnti/+fPn64MPPtCqVauOecwr3+HIkSM1d+5cnXbaadq5c6fuuusuffe739W6des8s4+bN2/W7NmzNX36dP3hD3/QqlWrdMMNNygzM1OTJk3y3L87ixYt0r59+3TNNddI8s5/V2fMmKFgMKj+/fsrPT1dtbW1uvvuuzVx4kRJifv9SPpggeRXUlKidevW6Z133nG7FMeddtppKisrU2VlpV588UVNmjRJy5Ytc7ssR5SXl2vq1Kl64403lJWV5XY5cRP5f3uSNHjwYI0cOVI9e/bU888/r+zsbBcrc044HNawYcN0zz33SJKGDBmidevW6dFHH9WkSZNcrs55Tz31lMaOHauioiK3S3HU888/r6efflrPPPOMTj/9dJWVlWnatGkqKipK6PeY9IdCOnXqpPT09GNm71ZUVKhLly4uVRU/kX3yyv5ef/31evXVV/X222+re/fudfd36dJFNTU12rdvX6PnJ9t+ZmZm6pRTTtHQoUNVWlqqM888Uw888IAn9m/NmjXavXu3zj77bGVkZCgjI0PLli3Tgw8+qIyMDBUWFib9PjYlPz9f/fr106ZNmzzxPUpS165dNXDgwEb3DRgwoO6Qj5f+3dm2bZvefPNN/fKXv6y7zyvf480336wZM2boJz/5ic444wz9/Oc/14033qjS0lJJifsekz5YZGZmaujQoVqyZEndfeFwWEuWLNGoUaNcrCw+evfurS5dujTa32AwqPfeey+p9tcYo+uvv14LFy7UW2+9pd69ezd6fOjQoWrTpk2j/Vy/fr22b9+eVPt5tHA4rFAo5In9u/DCC/Xxxx+rrKysbgwbNkwTJ06su53s+9iU/fv364svvlDXrl098T1K0ujRo49Z7r1hwwb17NlTknf+3ZGkOXPmqKCgQOPGjau7zyvf44EDB5SW1vhnPT09XeFwWFICv0fHpoG6aP78+cbv95u5c+eaTz/91Pz61782+fn5ZteuXW6XFpOqqiqzdu1as3btWiPJ3HfffWbt2rVm27Ztxhi7XCg/P9+8/PLL5qOPPjKXXXZZUi37MsaY6667zgQCAbN06dJGS8AOHDhQ95wpU6aYHj16mLfeesusXr3ajBo1yowaNcrFqqMzY8YMs2zZMrNlyxbz0UcfmRkzZhifz2f+8Y9/GGOSf/+a0nBViDHe2MebbrrJLF261GzZssX885//NGPGjDGdOnUyu3fvNsZ4Yx/ff/99k5GRYe6++26zceNG8/TTT5u2bduaefPm1T3HC//u1NbWmh49ephbbrnlmMe88D1OmjTJdOvWrW656YIFC0ynTp3M73//+7rnJOJ79ESwMMaYhx56yPTo0cNkZmaaESNGmJUrV7pdUszefvttI+mYMWnSJGOMXTJ0++23m8LCQuP3+82FF15o1q9f727RUWpq/ySZOXPm1D3n4MGD5j//8z9N+/btTdu2bc0VV1xhdu7c6V7RUZo8ebLp2bOnyczMNJ07dzYXXnhhXagwJvn3rylHBwsv7ONVV11lunbtajIzM023bt3MVVdd1ej8Dl7YR2OM+dvf/mYGDRpk/H6/6d+/v3n88ccbPe6Ff3cWL15sJDVZtxe+x2AwaKZOnWp69OhhsrKyTJ8+fcxtt91mQqFQ3XMS8T1y2XQAAOCYpJ9jAQAAWg+CBQAAcAzBAgAAOIZgAQAAHEOwAAAAjiFYAAAAxxAsAACAYwgWAADAMQQLAADgGIIFAABwDMECAAA4hmABAAAc8/8kVISx7mS8lQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(variance, \"r-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components is the matrix containing the 80 Eigen Vectors with the largest Eigen Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = pca.components_\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming XTrain, XValid and XTest from 784 to 80 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainTransformed = pca.transform(XTrain)\n",
    "XValidTransformed = pca.transform(XValid)\n",
    "XTestTransformed = pca.transform(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the same model as the first one just with the decrease in inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 14s 2ms/step - loss: 0.6922 - accuracy: 0.8149 - val_loss: 0.3588 - val_accuracy: 0.9037\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.3044 - accuracy: 0.9183 - val_loss: 0.2542 - val_accuracy: 0.9319\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.2305 - accuracy: 0.9386 - val_loss: 0.2072 - val_accuracy: 0.9443\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1922 - accuracy: 0.9488 - val_loss: 0.1798 - val_accuracy: 0.9515\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1676 - accuracy: 0.9556 - val_loss: 0.1623 - val_accuracy: 0.9564\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1504 - accuracy: 0.9606 - val_loss: 0.1510 - val_accuracy: 0.9593\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1374 - accuracy: 0.9643 - val_loss: 0.1404 - val_accuracy: 0.9623\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1272 - accuracy: 0.9668 - val_loss: 0.1324 - val_accuracy: 0.9643\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1185 - accuracy: 0.9692 - val_loss: 0.1274 - val_accuracy: 0.9661\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1113 - accuracy: 0.9712 - val_loss: 0.1224 - val_accuracy: 0.9672\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1051 - accuracy: 0.9728 - val_loss: 0.1171 - val_accuracy: 0.9685\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0996 - accuracy: 0.9747 - val_loss: 0.1141 - val_accuracy: 0.9700\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0947 - accuracy: 0.9758 - val_loss: 0.1104 - val_accuracy: 0.9703\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0903 - accuracy: 0.9770 - val_loss: 0.1073 - val_accuracy: 0.9711\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0863 - accuracy: 0.9779 - val_loss: 0.1050 - val_accuracy: 0.9715\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0826 - accuracy: 0.9790 - val_loss: 0.1032 - val_accuracy: 0.9722\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0792 - accuracy: 0.9799 - val_loss: 0.1015 - val_accuracy: 0.9725\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0760 - accuracy: 0.9807 - val_loss: 0.0987 - val_accuracy: 0.9739\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0732 - accuracy: 0.9815 - val_loss: 0.0974 - val_accuracy: 0.9740\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0703 - accuracy: 0.9823 - val_loss: 0.0955 - val_accuracy: 0.9740\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 0.0962 - val_accuracy: 0.9742\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0652 - accuracy: 0.9836 - val_loss: 0.0933 - val_accuracy: 0.9750\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0629 - accuracy: 0.9842 - val_loss: 0.0928 - val_accuracy: 0.9749\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0607 - accuracy: 0.9849 - val_loss: 0.0921 - val_accuracy: 0.9752\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0586 - accuracy: 0.9854 - val_loss: 0.0904 - val_accuracy: 0.9759\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0566 - accuracy: 0.9860 - val_loss: 0.0897 - val_accuracy: 0.9757\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0547 - accuracy: 0.9866 - val_loss: 0.0875 - val_accuracy: 0.9772\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.0870 - val_accuracy: 0.9771\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0511 - accuracy: 0.9874 - val_loss: 0.0857 - val_accuracy: 0.9773\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.0495 - accuracy: 0.9879 - val_loss: 0.0853 - val_accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[80])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "modelWithPca = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithPca.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = modelWithPca.fit(XTrainTransformed, yTrain, epochs=30, validation_data=(XValidTransformed, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was an approximately 3 minutes decrease in training time in comparison to the equivalent model with 784 dimensions with effectively the same accuracy (reduced from 97.7% to 97.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 4s 1ms/step - loss: 0.0900 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0900423601269722, 0.9767767190933228]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithPca.evaluate(XTestTransformed, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with 10 times less neurons and an additional hidden layer with 10 neurons. This was a test to see if decreasing neurons but increasing layers in a way that reduced the total no. of weights could potentially work. This one was not up to the mark (Time decrease of approx 1min with accuracy of 94.4%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 1.3666 - accuracy: 0.6103 - val_loss: 0.6813 - val_accuracy: 0.8084\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.5486 - accuracy: 0.8472 - val_loss: 0.4457 - val_accuracy: 0.8745\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.4136 - accuracy: 0.8849 - val_loss: 0.3731 - val_accuracy: 0.8964\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.3545 - accuracy: 0.9019 - val_loss: 0.3275 - val_accuracy: 0.9081\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.3178 - accuracy: 0.9114 - val_loss: 0.2986 - val_accuracy: 0.9165\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2934 - accuracy: 0.9186 - val_loss: 0.2817 - val_accuracy: 0.9208\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2748 - accuracy: 0.9242 - val_loss: 0.2643 - val_accuracy: 0.9263\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2610 - accuracy: 0.9279 - val_loss: 0.2573 - val_accuracy: 0.9286\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2510 - accuracy: 0.9308 - val_loss: 0.2474 - val_accuracy: 0.9310\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2426 - accuracy: 0.9333 - val_loss: 0.2432 - val_accuracy: 0.9335\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.2364 - accuracy: 0.9348 - val_loss: 0.2352 - val_accuracy: 0.9349\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2313 - accuracy: 0.9367 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2265 - accuracy: 0.9380 - val_loss: 0.2290 - val_accuracy: 0.9367\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2225 - accuracy: 0.9390 - val_loss: 0.2251 - val_accuracy: 0.9373\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2192 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9368\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2163 - accuracy: 0.9406 - val_loss: 0.2246 - val_accuracy: 0.9381\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2133 - accuracy: 0.9417 - val_loss: 0.2190 - val_accuracy: 0.9400\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2107 - accuracy: 0.9421 - val_loss: 0.2150 - val_accuracy: 0.9408\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2083 - accuracy: 0.9427 - val_loss: 0.2123 - val_accuracy: 0.9418\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2065 - accuracy: 0.9434 - val_loss: 0.2117 - val_accuracy: 0.9423\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2044 - accuracy: 0.9434 - val_loss: 0.2103 - val_accuracy: 0.9430\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2025 - accuracy: 0.9440 - val_loss: 0.2099 - val_accuracy: 0.9425\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.2007 - accuracy: 0.9447 - val_loss: 0.2087 - val_accuracy: 0.9428\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1990 - accuracy: 0.9454 - val_loss: 0.2069 - val_accuracy: 0.9435\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1974 - accuracy: 0.9459 - val_loss: 0.2045 - val_accuracy: 0.9438\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 10s 2ms/step - loss: 0.1962 - accuracy: 0.9461 - val_loss: 0.2082 - val_accuracy: 0.9438\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1947 - accuracy: 0.9466 - val_loss: 0.2040 - val_accuracy: 0.9442\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1933 - accuracy: 0.9470 - val_loss: 0.2025 - val_accuracy: 0.9446\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1919 - accuracy: 0.9473 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 11s 2ms/step - loss: 0.1912 - accuracy: 0.9472 - val_loss: 0.1992 - val_accuracy: 0.9454\n"
     ]
    }
   ],
   "source": [
    "input = keras.layers.Input(shape=[80])\n",
    "hidden1 = keras.layers.Dense(30, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=keras.activations.relu)(hidden1)\n",
    "hidden3 = keras.layers.Dense(10, activation=keras.activations.relu)(hidden2)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden3)\n",
    "modelWithPca = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithPca.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = modelWithPca.fit(XTrainTransformed, yTrain, epochs=30, validation_data=(XValidTransformed, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 3s 1ms/step - loss: 0.2074 - accuracy: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2073644995689392, 0.9441995620727539]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithPca.evaluate(XTestTransformed, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using a Supervised Feature Extraction Technique: Linear Discriminant Analysis. In most situations, LDA performs better than PCA but the shape of this dataset did not allow that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 14s 2ms/step - loss: 0.7047 - accuracy: 0.8147 - val_loss: 0.4527 - val_accuracy: 0.8738\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.3992 - accuracy: 0.8891 - val_loss: 0.3579 - val_accuracy: 0.8970\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3283 - accuracy: 0.9084 - val_loss: 0.3053 - val_accuracy: 0.9140\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2881 - accuracy: 0.9197 - val_loss: 0.2764 - val_accuracy: 0.9212\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2617 - accuracy: 0.9269 - val_loss: 0.2571 - val_accuracy: 0.9270\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2432 - accuracy: 0.9323 - val_loss: 0.2418 - val_accuracy: 0.9316\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2291 - accuracy: 0.9357 - val_loss: 0.2315 - val_accuracy: 0.9347\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2181 - accuracy: 0.9392 - val_loss: 0.2233 - val_accuracy: 0.9363\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2092 - accuracy: 0.9415 - val_loss: 0.2152 - val_accuracy: 0.9397\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2012 - accuracy: 0.9434 - val_loss: 0.2105 - val_accuracy: 0.9399\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1947 - accuracy: 0.9454 - val_loss: 0.2069 - val_accuracy: 0.9404\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1889 - accuracy: 0.9469 - val_loss: 0.2034 - val_accuracy: 0.9423\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1840 - accuracy: 0.9483 - val_loss: 0.2000 - val_accuracy: 0.9433\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1788 - accuracy: 0.9496 - val_loss: 0.1952 - val_accuracy: 0.9451\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1747 - accuracy: 0.9509 - val_loss: 0.1917 - val_accuracy: 0.9457\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1707 - accuracy: 0.9522 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1671 - accuracy: 0.9531 - val_loss: 0.1875 - val_accuracy: 0.9467\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1636 - accuracy: 0.9539 - val_loss: 0.1853 - val_accuracy: 0.9481\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.1605 - accuracy: 0.9546 - val_loss: 0.1854 - val_accuracy: 0.9473\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1575 - accuracy: 0.9557 - val_loss: 0.1814 - val_accuracy: 0.9488\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1544 - accuracy: 0.9564 - val_loss: 0.1815 - val_accuracy: 0.9488\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1515 - accuracy: 0.9573 - val_loss: 0.1812 - val_accuracy: 0.9485\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1492 - accuracy: 0.9578 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1464 - accuracy: 0.9582 - val_loss: 0.1778 - val_accuracy: 0.9491\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1439 - accuracy: 0.9593 - val_loss: 0.1752 - val_accuracy: 0.9507\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1416 - accuracy: 0.9595 - val_loss: 0.1765 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1392 - accuracy: 0.9606 - val_loss: 0.1744 - val_accuracy: 0.9506\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1373 - accuracy: 0.9611 - val_loss: 0.1720 - val_accuracy: 0.9517\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1353 - accuracy: 0.9614 - val_loss: 0.1731 - val_accuracy: 0.9508\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1330 - accuracy: 0.9621 - val_loss: 0.1719 - val_accuracy: 0.9511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=25)\n",
    "\n",
    "XTrainLda = lda.fit_transform(XTrain, yTrain)\n",
    "XValidLda = lda.transform(XValid)\n",
    "XTestLda = lda.transform(XTest)\n",
    "\n",
    "input = keras.layers.Input(shape=[25])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "modelWithLda = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithLda.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = modelWithLda.fit(XTrainLda, yTrain, epochs=30, validation_data=(XValidLda, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed worse not because of a problem inherent with LDA but because of the difference in the no. of dimensions and the no. of classes in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA, because of the Mathematics behind it, can reduce the dimensions to at most the minimum between the no. of Classes - 1 and the no. of original dimensions. In this dataset they were 26 and 784 respectively, so LDA could go at most 25, which could not retain as much information as needed about the original 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 4s 1ms/step - loss: 0.1794 - accuracy: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17941415309906006, 0.9482743740081787]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithLda.evaluate(XTestLda, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a test, let's see what happens if we apply LDA to the reduced dataset after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6540/6540 [==============================] - 13s 2ms/step - loss: 0.7091 - accuracy: 0.8117 - val_loss: 0.4498 - val_accuracy: 0.8737\n",
      "Epoch 2/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3991 - accuracy: 0.8882 - val_loss: 0.3517 - val_accuracy: 0.9000\n",
      "Epoch 3/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.3257 - accuracy: 0.9088 - val_loss: 0.3019 - val_accuracy: 0.9152\n",
      "Epoch 4/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2851 - accuracy: 0.9198 - val_loss: 0.2730 - val_accuracy: 0.9222\n",
      "Epoch 5/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2594 - accuracy: 0.9272 - val_loss: 0.2523 - val_accuracy: 0.9286\n",
      "Epoch 6/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2413 - accuracy: 0.9321 - val_loss: 0.2395 - val_accuracy: 0.9311\n",
      "Epoch 7/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2277 - accuracy: 0.9357 - val_loss: 0.2280 - val_accuracy: 0.9354\n",
      "Epoch 8/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2168 - accuracy: 0.9391 - val_loss: 0.2216 - val_accuracy: 0.9380\n",
      "Epoch 9/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2079 - accuracy: 0.9412 - val_loss: 0.2132 - val_accuracy: 0.9395\n",
      "Epoch 10/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.2004 - accuracy: 0.9435 - val_loss: 0.2071 - val_accuracy: 0.9412\n",
      "Epoch 11/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1941 - accuracy: 0.9451 - val_loss: 0.2036 - val_accuracy: 0.9424\n",
      "Epoch 12/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1885 - accuracy: 0.9468 - val_loss: 0.1995 - val_accuracy: 0.9435\n",
      "Epoch 13/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1833 - accuracy: 0.9485 - val_loss: 0.1971 - val_accuracy: 0.9434\n",
      "Epoch 14/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1785 - accuracy: 0.9498 - val_loss: 0.1948 - val_accuracy: 0.9444\n",
      "Epoch 15/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1741 - accuracy: 0.9509 - val_loss: 0.1911 - val_accuracy: 0.9460\n",
      "Epoch 16/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1701 - accuracy: 0.9519 - val_loss: 0.1884 - val_accuracy: 0.9465\n",
      "Epoch 17/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1667 - accuracy: 0.9528 - val_loss: 0.1860 - val_accuracy: 0.9475\n",
      "Epoch 18/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1631 - accuracy: 0.9541 - val_loss: 0.1827 - val_accuracy: 0.9489\n",
      "Epoch 19/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1598 - accuracy: 0.9548 - val_loss: 0.1835 - val_accuracy: 0.9477\n",
      "Epoch 20/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1567 - accuracy: 0.9558 - val_loss: 0.1810 - val_accuracy: 0.9483\n",
      "Epoch 21/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1538 - accuracy: 0.9563 - val_loss: 0.1798 - val_accuracy: 0.9495\n",
      "Epoch 22/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1508 - accuracy: 0.9570 - val_loss: 0.1784 - val_accuracy: 0.9494\n",
      "Epoch 23/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1483 - accuracy: 0.9574 - val_loss: 0.1756 - val_accuracy: 0.9501\n",
      "Epoch 24/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1457 - accuracy: 0.9588 - val_loss: 0.1732 - val_accuracy: 0.9507\n",
      "Epoch 25/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1430 - accuracy: 0.9594 - val_loss: 0.1734 - val_accuracy: 0.9508\n",
      "Epoch 26/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1409 - accuracy: 0.9601 - val_loss: 0.1742 - val_accuracy: 0.9501\n",
      "Epoch 27/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1385 - accuracy: 0.9603 - val_loss: 0.1702 - val_accuracy: 0.9522\n",
      "Epoch 28/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1364 - accuracy: 0.9612 - val_loss: 0.1694 - val_accuracy: 0.9520\n",
      "Epoch 29/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1342 - accuracy: 0.9620 - val_loss: 0.1690 - val_accuracy: 0.9528\n",
      "Epoch 30/30\n",
      "6540/6540 [==============================] - 12s 2ms/step - loss: 0.1324 - accuracy: 0.9621 - val_loss: 0.1653 - val_accuracy: 0.9537\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=25)\n",
    "\n",
    "XTrainLdaPca = lda.fit_transform(XTrainLda, yTrain)\n",
    "XValidLdaPca = lda.transform(XValidLda)\n",
    "XTestLdaPca = lda.transform(XTestLda)\n",
    "\n",
    "input = keras.layers.Input(shape=[25])\n",
    "hidden1 = keras.layers.Dense(300, activation=keras.activations.relu)(input)\n",
    "hidden2 = keras.layers.Dense(100, activation=keras.activations.relu)(hidden1)\n",
    "output = keras.layers.Dense(26, activation=keras.activations.softmax)(hidden2)\n",
    "modelWithLdaPca = keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "modelWithLdaPca.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = modelWithLdaPca.fit(XTrainLdaPca, yTrain, epochs=30, validation_data=(XValidLdaPca, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This somehow turned out slightly better with both a reduce in time and slightly improved accuracy. Was it just because of the randomness while initializing the weights or is there some reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907/2907 [==============================] - 4s 1ms/step - loss: 0.1741 - accuracy: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17408370971679688, 0.9513815641403198]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWithLdaPca.evaluate(XTestLdaPca, yTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
